# SNOMED Extraction Fix - Enhanced Instructions & Logging

## Problem

User asked "Show matching snomed codes" and the LLM responded:
```
âŒ "Could you clarify what you would like to match SNOMED codes to?
    Do you have a list of ICD-10 codes...?"
```

Even though:
- OHDSI field contains SNOMED mappings
- Context should be passed from session
- Instructions say "SNOMED codes are in OHDSI field"

## Root Cause

The LLM instructions weren't explicit enough about SNOMED requests specifically. The system message said SNOMED was in OHDSI, but didn't emphasize that ANY SNOMED request should immediately use the data.

## Solutions Implemented

### 1. Explicit SNOMED Warning

**File**: `modules/agents/chat_agent.py` (Line 78)

```python
âš ï¸ IMPORTANT: If the user asks for SNOMED codes, they are ALREADY in the OHDSI field below - DO NOT ask what to match, just extract them!
```

**Purpose**: Immediately visible warning before the data that SNOMED is already there.

### 2. Mandatory Numbered Rules

**File**: `modules/agents/chat_agent.py` (Lines 94-102)

```python
MANDATORY RULES:
1. NEVER ask the user to provide data - you already have ALL the data above
2. For ANY SNOMED request: Immediately parse the OHDSI field above and extract SNOMED codes
3. For "show snomed codes" or "matching snomed": Look at OHDSI field, find vocabulary_id="SNOMED", extract concept_code
4. Format the data as requested (table, JSON, list, etc.)
5. Do not add any additional codes or information not in the list above
6. If asked about codes not in the list, state they are not in the current dataset
7. When asked to create a table, use the data above immediately - do not ask for clarification
8. You have ALL the context needed - the OHDSI field contains the SNOMED mappings
```

**Key Changes**:
- Numbered list (easier to follow)
- Rule #2: "For ANY SNOMED request: Immediately parse..."
- Rule #3: Specific examples "show snomed codes", "matching snomed"
- Rule #8: Reinforces completeness

### 3. Enhanced Logging for Debugging

**File**: `modules/master_agent.py`

**Added logging points**:

```python
# Line 140: Classification logging
logger.info(f"ğŸ“‹ Agent classification: '{query}' â†’ agent_type='{agent_type}'")

# Line 167: Follow-up check logging
logger.info(f"ğŸ“‹ Checking follow-up: is_explicit_new_search={is_explicit_new_search}, is_concept_set={is_concept_set}")

# Line 170: Follow-up confirmed
logger.info(f"ğŸ“‹ âœ… Follow-up confirmed: Using chat agent with RAG context from session")

# Line 199: Standard routing (NOT follow-up)
logger.info(f"ğŸ“‹ Routing to '{agent_type}' agent (standard query path - NOT follow-up)")

# Line 207: Context passed with code count
logger.info(f"ğŸ“‹ State: Passing {num_codes} codes ({context_lines} lines) as context to chat agent")

# Line 211: Response WITH/WITHOUT context indicator
logger.info(f"ğŸ“‹ State: Chat response generated ({len(response)} chars) {'WITH' if context_str else 'WITHOUT'} context")
```

**Benefits**:
- See exactly which path the query took
- Know if follow-up was detected
- Confirm context was passed
- See code count being passed

## Expected Log Flow

### Scenario: "Show matching snomed codes" (Follow-up)

```
INFO - ğŸ“‹ Agent classification: 'Show matching snomed codes' â†’ agent_type='chat'
INFO - ğŸ“‹ Session check: has_session_data=True, session_id=streamlit_abc123
INFO - ğŸ“‹ Checking follow-up: is_explicit_new_search=False, is_concept_set=False
INFO - ğŸ“‹ âœ… Follow-up confirmed: Using chat agent with RAG context from session
INFO - ğŸ“‹ State: Retrieved 3 codes (18 lines) from session
INFO - ğŸ“‹ State: Response generated (245 chars) using session context with 3 codes
```

### Scenario: Falls to Standard Routing (Still gets context!)

```
INFO - ğŸ“‹ Agent classification: 'Show matching snomed codes' â†’ agent_type='chat'
INFO - ğŸ“‹ Session check: has_session_data=True, session_id=streamlit_abc123
INFO - ğŸ“‹ Checking follow-up: is_explicit_new_search=False, is_concept_set=True
INFO - ğŸ“‹ State initialized: agent_type='chat', user_input='Show matching snomed codes'
INFO - ğŸ“‹ Routing to 'chat' agent (standard query path - NOT follow-up)
INFO - ğŸ“‹ State: Passing 3 codes (18 lines) as context to chat agent
INFO - ğŸ“‹ State: Chat response generated (245 chars) WITH context
```

### Scenario: No Context (BUG - shouldn't happen!)

```
INFO - ğŸ“‹ Agent classification: 'Show matching snomed codes' â†’ agent_type='chat'
INFO - ğŸ“‹ Session check: has_session_data=False, session_id=streamlit_abc123
INFO - ğŸ“‹ State initialized: agent_type='chat', user_input='Show matching snomed codes'
INFO - ğŸ“‹ Routing to 'chat' agent (standard query path - NOT follow-up)
INFO - ğŸ“‹ State: âš ï¸ No session context available, using chat agent without RAG context
INFO - ğŸ“‹ State: Chat response generated (180 chars) WITHOUT context
```

## How It Should Work Now

```
User: "find diabetes codes"
  â†’ Stores: E10, E11, E13 with OHDSI field
  â†’ OHDSI contains: {"maps":[{"vocabulary_id":"SNOMED"...}]}

User: "Show matching snomed codes"
  â†“
Agent Classification: "chat" (no ICD keywords)
  â†“
Session Check: has_session_data = True âœ“
  â†“
Follow-up Detection:
  - is_explicit_new_search = False (no "new"/"different")
  - is_concept_set = False
  â†’ Follow-up = True âœ“
  â†“
Get Context with 3 codes and OHDSI fields
  â†“
System Message includes:
  "âš ï¸ IMPORTANT: If user asks for SNOMED, they are ALREADY in OHDSI field - DO NOT ask, just extract!
   
   MANDATORY RULES:
   2. For ANY SNOMED request: Immediately parse OHDSI field...
   3. For 'show snomed codes': Look at OHDSI, find vocabulary_id='SNOMED'...
   
   AVAILABLE ICD-10 CODES (3 codes):
   [E10] Type 1 diabetes...
     OHDSI: {\"maps\":[{\"vocabulary_id\":\"SNOMED\",\"concept_code\":\"46635009\"...}]}
   [E11] Type 2 diabetes...
     OHDSI: {\"maps\":[{\"vocabulary_id\":\"SNOMED\",\"concept_code\":\"44054006\"...}]}
   [E13] Other diabetes...
     OHDSI: {\"maps\":[{\"vocabulary_id\":\"SNOMED\",\"concept_code\":\"190372001\"...}]}"
  â†“
LLM Sees:
  - Warning: SNOMED already in OHDSI
  - Rule #2: For ANY SNOMED request â†’ parse immediately
  - Data: 3 codes with OHDSI fields
  â†“
LLM Action:
  1. Parse OHDSI field for each code
  2. Find vocabulary_id="SNOMED"
  3. Extract concept_code
  4. Display results
  â†“
Response:
  "SNOMED Codes:
   - E10 â†’ 46635009 (Diabetes mellitus type 1)
   - E11 â†’ 44054006 (Diabetes mellitus type 2)
   - E13 â†’ 190372001 (Other specified diabetes mellitus)"
```

## Debugging Steps

If "Show matching snomed codes" still asks for clarification:

### Step 1: Check Logs - Was it Follow-up?
```bash
grep "ğŸ“‹" | grep "Show matching snomed"
```

Look for:
- âœ… "Follow-up confirmed" â†’ Good path
- âŒ "standard query path - NOT follow-up" â†’ Still should get context, but check next

### Step 2: Check Context Was Passed
```bash
grep "ğŸ“‹ State: Passing" | tail -1
```

Look for:
- âœ… "Passing 3 codes (18 lines)" â†’ Context passed
- âŒ "No session context available" â†’ BUG - session lost

### Step 3: Check Response Generation
```bash
grep "ğŸ“‹ State: Chat response generated" | tail -1
```

Look for:
- âœ… "generated (245 chars) WITH context" â†’ Context used
- âŒ "generated (180 chars) WITHOUT context" â†’ No context passed

### Step 4: If Context WAS Passed but LLM Still Asked
This means LLM is ignoring instructions. Try:
1. Increase temperature to 0.0 in chat_agent config
2. Try different model (GPT-4 vs GPT-3.5)
3. Check if context string is actually populated (print it)

## Test Sequence

```bash
source .venv/bin/activate
streamlit run main.py
```

Try:
1. "find diabetes codes" â†’ Should store E10, E11, E13
2. Check logs: `grep "Stored.*codes with OHDSI"`
3. "show matching snomed codes" â†’ Should extract immediately
4. Check logs: Look for "Follow-up confirmed" and "Passing 3 codes"

Expected response:
```
SNOMED Codes from the ICD-10 codes in our dataset:

- **E10** (Type 1 diabetes mellitus without complications)
  â†’ SNOMED: 46635009 - Diabetes mellitus type 1

- **E11** (Type 2 diabetes mellitus without complications)  
  â†’ SNOMED: 44054006 - Diabetes mellitus type 2

- **E13** (Other specified diabetes mellitus without complications)
  â†’ SNOMED: 190372001 - Other specified diabetes mellitus
```

## Files Modified

1. âœ… `modules/agents/chat_agent.py` - Added explicit SNOMED warning + numbered rules
2. âœ… `modules/master_agent.py` - Enhanced logging at all decision points

## Summary

**Enhanced LLM instructions with explicit SNOMED handling:**
- âš ï¸ Warning: SNOMED already in OHDSI field
- Rule #2: ANY SNOMED request â†’ parse immediately
- Rule #3: Specific examples of SNOMED requests
- Rule #8: Reinforces completeness

**Comprehensive logging added:**
- ğŸ“‹ Agent classification
- ğŸ“‹ Follow-up detection with boolean values
- ğŸ“‹ Context passing with code counts
- ğŸ“‹ Response generation WITH/WITHOUT indicator

**The LLM should now immediately extract SNOMED codes from OHDSI field without asking for clarification!**
